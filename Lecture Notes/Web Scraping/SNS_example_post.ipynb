{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>An example of SNS</center>\n",
    "\n",
    "- Threadless.com is a crowdsouring website for graphic designs.\n",
    "- Desginers submit artworks and recieve ratings from the community within a seven-day period. \n",
    "- Designs with the best scores will be selected to print on T-shirts and other products for sale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping objectives\n",
    "\n",
    "- Get a sample of users and artifacts. Consider a sampling strategy. \n",
    "- Scrape artifact-level features.\n",
    "- Scrape user-level features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.threadless.com/designs/archive?page=1', 'https://www.threadless.com/designs/archive?page=2', 'https://www.threadless.com/designs/archive?page=3', 'https://www.threadless.com/designs/archive?page=4', 'https://www.threadless.com/designs/archive?page=5']\n"
     ]
    }
   ],
   "source": [
    "# Get five urls of pages as a sample of latest artifacts.\n",
    "\n",
    "link=\"https://www.threadless.com/designs/archive?page=\"\n",
    "num=list(range(1,6))\n",
    "pages=[]\n",
    "for i in num:\n",
    "    page=link+str(i)\n",
    "    pages.append(page)\n",
    "print(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on page https://www.threadless.com/designs/archive?page=1\n",
      "working on page https://www.threadless.com/designs/archive?page=2\n",
      "working on page https://www.threadless.com/designs/archive?page=3\n",
      "working on page https://www.threadless.com/designs/archive?page=4\n",
      "working on page https://www.threadless.com/designs/archive?page=5\n"
     ]
    }
   ],
   "source": [
    "# Get urls of all the designs in these pages\n",
    "# To reduce the load to their server, will demonnstrate one page\n",
    "\n",
    "designs=[]\n",
    "for i in pages:\n",
    "    print('working on page'+str(' ')+str(i))\n",
    "    response=requests.get(i)\n",
    "    soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "    links=soup.find('ol',class_='feed-archive th-grided')\n",
    "    li=links.find_all('li',class_=\"old\")\n",
    "    for j in li:\n",
    "        name=j.find(\"a\")[\"href\"]\n",
    "        designs.append(name)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/designs/sacred-tree-of-life',\n",
       " '/designs/colorful-origami-giraffe',\n",
       " '/designs/origami-giraffe',\n",
       " '/designs/y2k-is-here',\n",
       " '/designs/broken-angel-3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designs[:5]\n",
    "\n",
    "# can write out the sample of artifacts \n",
    "# with open('designs.csv', 'w') as csvfile:\n",
    "#    writer=csv.writer(csvfile, delimiter=',')\n",
    "#    writer.writerows(zip(designs))\n",
    "\n",
    "\n",
    "# read in your sample\n",
    "# raw_data_file = open(\"designs.csv\", 'r')\n",
    "# csv_data_file = csv.reader(raw_data_file, delimiter=',')\n",
    "# designs = []\n",
    "# for line in csv_data_file:\n",
    "#     print(line[0])\n",
    "#     designs.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sacred tree of life', 'Bearpaws', '2.00', '2')\n",
      "('Colorful Origami Giraffe', 'koalafish', '3.67', '3')\n",
      "('Origami Giraffe', 'koalafish', '1.00', '1')\n",
      "('Y2K is here', 'Producershirts', '2.00', '4')\n",
      "('Broken Angel', 'RIZES', [], '0')\n",
      "('wolf art', 'nafidie', '2.25', '4')\n",
      "('Montana Rainbow', 'tanavegas', '1.00', '1')\n",
      "(\"You're Perfect\", 'losereputation', '3.25', '4')\n",
      "('Dead inside But coffeimated AF', 'urbrand', '3.33', '3')\n",
      "('coffee lover', 'urbrand', '3.50', '4')\n",
      "('ENVIRONMENT LOGO CLEAN CITY', 'nafidie', '2.00', '4')\n",
      "('coffee valentines', 'urbrand', '2.33', '3')\n",
      "('ENVIRONMENT LOGO TREE', 'nafidie', '2.00', '3')\n",
      "('Cloudy Day', 'braxxaz', '3.00', '2')\n",
      "('Owl With coffee', 'urbrand', '2.67', '3')\n",
      "('ENVIRONMENT LOGO HAND TREE', 'nafidie', '2.00', '3')\n",
      "('Owl Valentines Day', 'urbrand', '3.00', '3')\n",
      "('Owl Lovers', 'urbrand', '3.33', '3')\n",
      "('Love owl', 'urbrand', '3.33', '3')\n",
      "('Hello Sunshine', 'braxxaz', '1.00', '1')\n",
      "(\"I'm Your Father Nooo Floppy Disc And USB Y2K\", 'Smart-creator', '1.00', '3')\n",
      "('cute owl', 'urbrand', '3.00', '3')\n",
      "('Cats lovers', 'urbrand', '3.67', '3')\n",
      "('Cassette Tapes Y2K', 'Smart-creator', '2.20', '5')\n",
      "('cats valentines day', 'urbrand', '4.10', '10')\n",
      "('Achilles - Greek Warrior', 'portokalis', '1.00', '1')\n",
      "('Achilles - Greek Warrior', 'portokalis', '1.00', '1')\n",
      "('Lost in Years', 'Rabica', '2.00', '8')\n",
      "('Calm', 'Keejus', '2.33', '3')\n",
      "('King of own Kingdom.', 'Rabica', '2.00', '1')\n",
      "('Metal Skull Close-Up', 'VaporwaveAI', '1.00', '3')\n",
      "('Bring me back to the 90s', 'stotaz9', '1.60', '5')\n",
      "('Perfection Wood Screws vintage box label', 'mattjh2', '1.00', '1')\n",
      "('Skull In Space', 'VaporwaveAI', '2.33', '3')\n",
      "('Nappa', 'GloopZ', '4.40', '5')\n",
      "('Space temptations', 'makart', '3.60', '20')\n",
      "('\"Environmentalist\" the Fake Govt. Facade', 'ClothingnCrypto', '2.67', '6')\n",
      "('The Captain', 'JPArts26', '3.00', '5')\n",
      "('Blackfoot', 'bojanvukovic', '4.02', '42')\n",
      "('The Captain', 'JPArts26', '3.83', '6')\n"
     ]
    }
   ],
   "source": [
    "# Get artifact level features\n",
    "# For each design, get title, author, average score, number of scores, challenge name\n",
    "\n",
    "rows=[]\n",
    "\n",
    "for i in designs[:40]:\n",
    "    try:\n",
    "        url=\"https://www.threadless.com\"+i\n",
    "        response=requests.get(url)\n",
    "        soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # initiate the variable for each period\n",
    "        title=None\n",
    "        author=None\n",
    "        avg_score=None\n",
    "        total_score=None\n",
    "        \n",
    "        ##title\n",
    "        title=soup.select('div.submission-title h1')\n",
    "        if title!=[]:\n",
    "            title=title[0].text\n",
    "\n",
    "        ##author\n",
    "        author=soup.select('div.author-block a.author')\n",
    "        if author!=[]:\n",
    "            author=author[0].text\n",
    "\n",
    "        ##score\n",
    "        avg_score=soup.select('li.avg-score strong')\n",
    "        if avg_score!=[]:\n",
    "            avg_score=avg_score[0].text\n",
    "\n",
    "        ##total scores\n",
    "        total_score=soup.select('li.total-scores strong')\n",
    "        if total_score!=[]:\n",
    "            total_score=total_score[0].text\n",
    "        \n",
    "        rows.append((title, author, avg_score, total_score))\n",
    "        print((title, author, avg_score, total_score))\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threadless\n",
      " 132137 designs\n",
      "\n",
      "Y2K\n",
      " 795 designs\n",
      "\n",
      "Pride Forever\n",
      " 2154 designs\n",
      "\n",
      "Horror\n",
      " 5505 designs\n",
      "\n",
      "Threadless\n",
      " 132137 designs\n"
     ]
    }
   ],
   "source": [
    "# Question: How to scrape the challenge information?\n",
    "\n",
    "# 1. challenge name\n",
    "# 2. how many designs per challenge\n",
    "\n",
    "\n",
    "# add your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JPArts26', 'Bearpaws', 'Smart-creator', 'losereputation', 'tanavegas', 'mattjh2', 'nafidie', 'GloopZ', 'koalafish', 'VaporwaveAI', 'Producershirts', 'braxxaz', 'Keejus', 'ClothingnCrypto', 'portokalis', 'Rabica', 'makart', 'urbrand', 'bojanvukovic', 'stotaz9', 'RIZES']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get authors\n",
    "authors=[row[1] for row in rows]\n",
    "authors=filter(None, authors)\n",
    "authors_unique=list(set(authors))\n",
    "print(authors_unique)\n",
    "len(authors_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5 threads started', '125 designs submitted', '45 designs scored', 'Avg Score Given: 4.69', 'Member since 2015', 'Producershirts']\n",
      "[None, '11 designs submitted', None, 'Avg Score Given: 0.00', 'Member since 2022', 'urbrand']\n",
      "[None, '47 designs submitted', '7 designs scored', 'Avg Score Given: 4.43', 'Member since 2019', 'braxxaz']\n",
      "['2 threads started', '64 designs submitted', '21 designs scored', 'Avg Score Given: 1.52', 'Member since 2022', 'Bearpaws']\n",
      "[None, '9 designs submitted', '1 design scored', 'Avg Score Given: 5.00', 'Member since 2023', 'nafidie']\n"
     ]
    }
   ],
   "source": [
    "# For the designers we found, get the summary of their experience\n",
    "full=[]\n",
    "\n",
    "for i in authors_unique[:5]:\n",
    "    url=\"https://www.threadless.com/@\"+i\n",
    "    time.sleep(5)\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # find all stats\n",
    "    stats=soup.select('div.stats ul')\n",
    "    li=stats[0].find_all('li')\n",
    "    \n",
    "    line=[None] * 5\n",
    "    for j in li:\n",
    "        char=(j.text).strip()\n",
    "        \n",
    "        # threads\n",
    "        if re.search(\"started\",char):\n",
    "            line[0]=char\n",
    "            #line[1]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "            \n",
    "        # submitted\n",
    "        if re.search(\"submitted\",char):\n",
    "            line[1]=char   \n",
    "            #line[1]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "\n",
    "        # scored\n",
    "        if re.search(\"scored\",char):\n",
    "            line[2]=char\n",
    "            #line[2]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "        \n",
    "        # given\n",
    "        if re.search(\"Given\",char):\n",
    "            line[3]=char\n",
    "            #line[3]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "\n",
    "        # since\n",
    "        if re.search(\"since\",char):\n",
    "            line[4]=char\n",
    "            #line[4]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "    \n",
    "    line.append(i)\n",
    "    print(line)\n",
    "    full.append(line)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producershirts 34 268\n",
      "urbrand 0 6\n",
      "braxxaz 0 41\n",
      "Bearpaws 15 13\n",
      "nafidie 1 4\n"
     ]
    }
   ],
   "source": [
    "# Question: how to scrape each designers' numbers of followers and following?\n",
    "\n",
    "\n",
    "\n",
    "# add you code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the follower-followee network for each designer.\n",
    "# Can we do this with beautifulsoup? \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GloopZ', 'makart']\n",
      "['Keejus', 'koalafish']\n",
      "['ClothingnCrypto', 'koalafish']\n",
      "['Keejus', 'VaporwaveAI']\n",
      "['Keejus', 'braxxaz']\n",
      "['portokalis', 'Keejus']\n",
      "['Keejus', 'GloopZ']\n",
      "['Keejus', 'koalafish']\n",
      "['Keejus', 'portokalis']\n",
      "['Keejus', 'makart']\n",
      "['Keejus', 'braxxaz']\n",
      "['Keejus', 'VaporwaveAI']\n",
      "['ClothingnCrypto', 'koalafish']\n",
      "['ClothingnCrypto', 'makart']\n",
      "['Keejus', 'portokalis']\n",
      "['portokalis', 'Keejus']\n"
     ]
    }
   ],
   "source": [
    "relations=[]\n",
    "\n",
    "for i in authors_unique:\n",
    "    \n",
    "    i=i.replace(\" \",\"%20\")\n",
    "    \n",
    "    follower_url=\"https://www.threadless.com/@\"+i+\"/followers\"\n",
    "    following_url=\"https://www.threadless.com/@\"+i+\"/following\"\n",
    "\n",
    "    # close a pop ad\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=gene\")\n",
    "    driver = webdriver.Chrome(options=opts)\n",
    "\n",
    "    # one's follower   \n",
    "    driver.get(follower_url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # you can scroll many times if not reaching the end\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  \n",
    "    time.sleep(10)        \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html.encode('utf-8'),\"html.parser\")\n",
    "    comp=soup.find('ol',class_=\"following-list\")\n",
    "    comp=comp.find_all(\"li\")\n",
    "\n",
    "    line=[]\n",
    "    for k in comp:\n",
    "        name=k.find(\"a\")[\"href\"]\n",
    "        name=name.lstrip(\"/@\")\n",
    "        if name in authors_unique:\n",
    "            # one's followers send the following tie\n",
    "            line=[name, i]\n",
    "            print(line)\n",
    "            relations.append(line)\n",
    "    \n",
    "    # one's follwing\n",
    "    driver.get(following_url)\n",
    "    time.sleep(10)   \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")                \n",
    "    time.sleep(25)  \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html.encode('utf-8'),\"html.parser\")\n",
    "    comp=soup.find('ol',class_=\"following-list\")\n",
    "    comp=comp.find_all(\"li\")\n",
    "\n",
    "    line=[]\n",
    "    for k in comp:\n",
    "        name=k.find(\"a\")[\"href\"]\n",
    "        name=name.lstrip(\"/@\")\n",
    "        if name in authors_unique:\n",
    "            # one sends the following tie to those to follow\n",
    "            line=[i, name]\n",
    "            print(line)\n",
    "            relations.append(line)\n",
    "    driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
